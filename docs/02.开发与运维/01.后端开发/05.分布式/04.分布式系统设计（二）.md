---
date: 2025-02-21 00:00:00
author: 
  name: northboat
  link: https://github.com/northboat
title: 分布式系统设计（二）
permalink: /pages/4f5b6d/
---

## 消息队列 MQ

### 消息队列模型

队列模型，又叫点对点模型，每个生产者对应一个消费者（一对一）

- 比如 OJ 中 MQ 的使用，后端收到判题请求后，先将判题记录写入数据库，而后作为生产者将判题记录 ID 写入消息队列，此时真正的判题模块由于订阅了该判题队列，于是自动从 MQ 中读出判题请求 ID，从 DB 中拿取数据执行判题业务，最后通过 WebSocket 返回

订阅发布模型，一个生产者将把消息广播到每一个订阅者，即一对多

订阅发布能够将串行执行的任务变成“并行”，例如以下串行场景，他是一步步执行

<img src="./assets/image-20250303143017426.png">

若引入 MQ，它可以变成这样的形式，这是合理的，实际上，更新积分、通知商家、更新用户标签这三个事件并没有直接的逻辑联系或是执行顺序问题，他们都是由“更新订单状态触发”

<img src="./assets/image-20250303143143342.png">

从而大幅提高效率

上述订阅发布模式的举例是 MQ 一大应用场景，**异步处理**，而队列模式的举例是**应用解耦**，消息队列的常用场景如下

- 异步处理：就是将一些非核心的业务流程以异步并行的方式执行，从而减少请求响应时间，提高系统吞吐量
- 应用解耦：顾名思义就是解除应用系统之间的耦合依赖。通过消息队列，使得每个应用系统不必受其他系统影响，可以更独立自主运行
- 流量削峰：是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛
- 消息通讯：指应用间的数据通信，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等点对点通讯

### RabbitMQ

现有一些开源 MQ 的对比

| 特性\消息队列 | Kafka                                                        | RocketMQ                                                     | RabbitMQ                                                     | ActiveMQ                                                     |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量    | 10万级                                                       | 10万级                                                       | 万级                                                         | 10万级                                                       |
| 开发语言      | Scala                                                        | Java                                                         | Erlang                                                       | Java                                                         |
| 高可用        | 分布式                                                       | 分布式                                                       | 主从                                                         | 分布式                                                       |
| 消息延迟      | ms级                                                         | ms级                                                         | us级                                                         | ms级                                                         |
| 消息丢失      | 理论上不会丢失                                               | 理论上不会丢失                                               | 低                                                           | 低                                                           |
| 消费模式      | 拉取                                                         | 推拉                                                         | 推拉                                                         |                                                              |
| 持久化        |                                                              | 文件                                                         | 内存，文件                                                   | 内存，文件，数据库                                           |
| 支持协议      | 自定义协议                                                   | 自定义协议                                                   | AMQP，XMPP, SMTP,STOMP                                       | AMQP,MQTT,OpenWire,STOMP                                     |
| 社区活跃度    | 高                                                           | 中                                                           | 高                                                           | 高                                                           |
| 管理界面      |                                                              | web console                                                  | 好                                                           | 一般                                                         |
| 部署难度      | 中                                                           |                                                              | 低                                                           |                                                              |
| 部署方式      | 独立                                                         | 独立                                                         | 独立                                                         | 独立，嵌入                                                   |
| 成熟度        | 成熟                                                         | 比较成熟                                                     | 成熟                                                         | 成熟                                                         |
| 综合评价      | 优点：拥有强大的性能及吞吐量，兼容性很好。 缺点：由于支持消息堆积，导致延迟比较高 | 优点：性能好，稳定可靠，有活跃的中文社区，特点响应快。 缺点：兼容性较差，但随着影响力的扩大，该问题会有改善 | 优点：产品成熟，容易部署和使用，拥有灵活的路由配置。 缺点：性能和吞吐量较差，不易进行二次开发 | 优点：产品成熟，支持协议多，支持多种语言的客户端。 缺点：社区不活跃，存在消息丢失的可能 |

引入 RabbitMQ 依赖

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

配置文件

```yaml
spring:
	rabbitmq:
		host: 10.2.1.231
		port: 5672
		username: northboat
		password: 123456
		virtualHost: order
```

一个简单的消费者，订阅队列"`rabbitmq_queue"`

```java
@Component
public class Consumer {
	@RabbitHandler
	@RabbitListener(queuesToDeclare = @Queue("rabbitmq_queue"))
	public void process(String message) {
		System.out.println("消费者消费消息: " + message);
	}
}
```

一个简单的生产者

```java
@Component
public class Producer {
	@Autowired
	private RabbitTemplate rabbitTemplate;
	
	public void produce() {
		String message = new Date() + "Beijing";
		System.out.println("生产者产生消息: " + message);
		rabbitTemplate.convertAndSend("rabbitmq_queue", message);
	}
}
```

这里传输的是简单字符串，我们尝试传输一个实体对象 User，需要进行序列化，即继承`Serializable`类

```java
public class User implements Serializable {
	public String name;
	public String password;
	// 省略get和set方法
}
```

仍然通过`convertAndSend`方法进行传输

```java
@Component
public class Producer {
	@Autowired
	private RabbitTemplate rabbitTemplate;
	
	public void produce() {	
		User user = new User("nmsl", "wdnmd");
		System.out.println("生产者生产消息: " + user);
		
		rabbitTemplate.convertAndSend("rabbitmq_queue_object", user);
	}
}
```

convertAndSend() 方法支持 String、Integer、Object 等基础的数据类型

### 确保可靠传输

在使用消息队列时，因为生产者和消费者不直接交互，所以面临下面几个问题

1. 要把消息添加到队列中，怎么保证消息成功添加？
2. 如何保证消息发送出去时一定会被消费者正常消费？
3. 消费者正常消费了，生产者或者队列如何知道消费者已经成功消费了消息？

那么，如何保证消息 100% 可靠性发送？我们可以采用 ack 应答 + 日志记录 + 定时任务来实现

假设有一个创建订单业务，后端收到请求后，将该业务通过消息队列发送到具体的业务模块，我们这样保证消息的可靠传输

1. 完成订单业务处理后，生产者发送一条消息到消息队列，同时记录这条操作日志（发送中）
2. 消费者收到消息后处理进行
3. 消费者处理成功后给消息队列发送 ack 应答
4. 消息队列收到 ack 应答后，给生成者的 Confirm Listener 发送确认
5. 生产者对消息日志表进行操作，修改之前的日志状态（发送成功）
6. 在消费端返回应答的过程中，可能发生网络异常，导致生产者未收到应答消息，因此需要一个定时任务去提取其状态为“发送中”并已经超时的消息集合
7. 使用定时任务判断为消息事先设置的最大重发次数，大于最大重发次数就判断消息发送失败，更新日志记录状态为发送失败

流程图如下

<img src="./assets/48247e3cabbd4c2085defccd1ea67f7b.png">

具体实现

1️⃣ 创建生产者

定义应答方法`final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() {}`，即定义收到消费者发回的 ack 应答后的处理：更新日志记录，修改订单状态为成功

```java
@Component
public class RabbitOrderSender {
    private static Logger logger = LoggerFactory.getLogger(RabbitOrderSender.class);

    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Autowired
    private MessageLogMapper messageLogMapper;

    /**
     * Broker应答后，会调用该方法区获取应答结果
     */
    final RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() {
        @Override
        public void confirm(CorrelationData correlationData, boolean ack, String cause) {
            logger.info("correlationData："+correlationData);
            String messageId = correlationData.getId();
            logger.info("消息确认返回值："+ack);
            if (ack){
                //如果返回成功，则进行更新
                messageLogMapper.changeMessageLogStatus(messageId, Constans.ORDER_SEND_SUCCESS,new Date());
            }else {
                //失败进行操作：根据具体失败原因选择重试或补偿等手段
                logger.error("异常处理,返回结果："+cause);
            }
        }
    };

    /**
     * 发送消息方法调用: 构建自定义对象消息
     * @param order
     * @throws Exception
     */
    public synchronized void  sendOrder(OrderInfo order) throws Exception {
        // 通过实现 ConfirmCallback 接口，消息发送到 Broker 后触发回调，确认消息是否到达 Broker 服务器，也就是只确认是否正确到达 Exchange 中
        rabbitTemplate.setConfirmCallback(confirmCallback);
        //消息唯一ID
        CorrelationData correlationData = new CorrelationData(order.getMessageId());
        rabbitTemplate.convertAndSend("order.exchange", "order.message", order, correlationData);
    }
}
```

当生产者调用`ConfirmCallback()`，说明当前请求已被消费者消费

2️⃣ 定义消息定时重发任务

定期去数据库中找状态为 0 的数据项，进行消息重发

- 通过`@Compoent`和`@Scheduled(initialDelay = 5000, fixedDelay = 10000)`注解将定时任务注入 Spring，初始 5 s 后开始执行，往后每 10s 执行一次
- 判断逻辑为：当重发大于两次，认为任务失败，不再执行，否则通过 RabbitOrderSender 进行重发

```java
@Component
public class RetryMessageTasker {
    private static Logger logger = LoggerFactory.getLogger(RetryMessageTasker.class);
    @Autowired
    private RabbitOrderSender rabbitOrderSender;

    @Autowired
    private MessageLogMapper messageLogMapper;

    /**
     * 定时任务
     */
    @Scheduled(initialDelay = 5000, fixedDelay = 10000)
    public void reSend(){
        logger.info("-----------定时任务开始-----------");
        //抽取消息状态为0且已经超时的消息集合
        List<MessageLog> list = messageLogMapper.query4StatusAndTimeoutMessage();
        list.forEach(messageLog -> {
            //投递三次以上的消息
            if(messageLog.getTryCount() >= 3){
                //更新失败的消息
                messageLogMapper.changeMessageLogStatus(messageLog.getMessageId(), Constans.ORDER_SEND_FAILURE, new Date());
            } else {
                // 重试投递消息，将重试次数递增
                messageLogMapper.update4ReSend(messageLog.getMessageId(),  new Date());
                OrderInfo reSendOrder = JsonUtil.jsonToObject(messageLog.getMessage(), OrderInfo.class);
                try {
                    rabbitOrderSender.sendOrder(reSendOrder);
                } catch (Exception e) {
                    e.printStackTrace();
                    logger.error("-----------异常处理-----------");
                }
            }
        });
    }
}
```

3️⃣ 运行测试

```java
@RunWith(SpringRunner.class)
@SpringBootTest
public class MqApplicationTests {
    @Autowired
    private OrderService orderService;

    /**
     * 测试订单创建
     */
    @Test
    public void createOrder(){
        OrderInfo order = new OrderInfo();
        order.setId("201901236");
        order.setName("测试订单6");
        order.setMessageId(System.currentTimeMillis() + "$" + UUID.randomUUID().toString());
        try {
            orderService.createOrder(order);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

}
```

### 消息队列的选择

Kafka 设计之初是用于处理大批量的日志，基于自定义的二进制协议，专注于高吞吐量，其特点如下

而 RabbitMQ 的设计目标是**低延迟**和**可靠传递**，它的消息确认机制和重试机制可以确保任务被正确处理，适合高并发的任务，常用于业务的解耦、异步处理

| 消息队列 | 协议                                                         | 消息传输                                                     | 实时性                 | 扩展性                                                  | 持久化                                     |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------- | ------------------------------------------------------- | ------------------------------------------ |
| Kafka    | 基于自定义的二进制协议，专注于高吞吐量                       | 消息以**日志**的形式持久化存储，支持高吞吐量的消息流；不支持消息确认（ACK）和重试机制，但可以通过消费者偏移量（Offset）实现消息重放 | 延迟较高，适合批量处理 | 支持分布式集群，可以轻松扩展到数百个节点，处理海量数据  | 消息持久化到磁盘，支持长期存储和回溯       |
| RabbitMQ | 基于 AMQP（Advanced Message Queuing Protocol），支持多种消息模式（如点对点、发布/订阅） | 支持消息确认（ACK）和重试机制，确保消息可靠传递；支持消息优先级、延迟队列、死信队列等高级特性 | 适合低延迟的消息传递   | 支持复杂的路由规则（如 direct、topic、fanout 等交换器） | 可以通过集群实现高可用性，但扩展性相对有限 |

什么是 AMQP（Advanced Message Queuing Protocol）

RabbitMQ 的适用场景

- 任务队列：适合需要**实时处理**的任务，例如 Web 应用中的异步任务（如发送邮件、处理订单）
- 低延迟场景：需要**快速响应**的场景，例如实时通知、即时消息
- 复杂路由：需要根据消息内容或规则将消息路由到不同消费者的场景
- 可靠传递：需要确保**每条消息都被正确处理**，适合对消息丢失敏感的场景

Kafka 使用场景

- 日志收集：适合收集和存储大量日志数据，例如应用程序日志、系统日志
- 流处理：适合实时**流处理场景**，例如用户行为分析、实时推荐系统
- 大数据管道：适合作为**大数据**生态系统的数据传输管道，例如将数据从生产系统传输到 Hadoop 或 Spark
- 事件溯源：适合需要**记录事件历史**的场景，例如金融交易记录、审计日志（因为数据会写入磁盘进行持久化）

选择 RabbitMQ 的场景

- 你需要低延迟的消息传递
- 你需要复杂的路由规则（如根据消息内容路由到不同消费者）
- 你需要确保每条消息都被正确处理（如金融交易、订单处理）
- 你的系统规模较小或中等，不需要处理海量数据

选择 Kafka 的场景

- 你需要高吞吐量的消息处理（如日志收集、用户行为分析）
- 你需要持久化存储消息，并且可能需要回溯历史消息
- 你需要流处理能力（如实时推荐、实时监控）
- 你的系统规模较大，需要处理海量数据。

RabbitMQ 为什么 RabbitMQ 并发能力强于 Kafka 而 Kafka 吞吐量大于 RabbitMQ？

首先回答吞吐量的问题

1. Kafka 的吞吐量高很大原因来自于其**批处理**设计，将多个消息打包成一个批次来减少网络和磁盘 I/O 的开销，相应的，这样处理的延迟会变大
2. 另外，Kafka 不仅仅是一个消息队列，它还提供了 Kafka Streams 和 Kafka Connect 等工具，用于实现**流处理**，从而大大提高数据处理速度

什么是批处理，什么是流处理？

- 批处理是指对**静态的、有限的数据集**进行处理。数据通常以文件或数据库表的形式存储，处理过程是周期性的（如每天、每小时）
- 流处理是指对**连续的、无限的数据流**进行实时或近实时的处理。数据通常是动态生成的（如日志、传感器数据、用户行为数据）

💤 PS：流处理让我想到 Java Stream 流，虽然都叫“流”，但 Java Stream 实际上是一个用于对集合（Collection）数据进行函数式操作（如过滤、映射、排序、聚合等）的 API，提供一种更简洁、更高效的方式来处理集合数据（所谓函数式编程）

而 RabbitMQ 的高并发显著强于 Kafka，首先我们要明确到底什么是并发能力强，并发能力强并不是只 QPS（Queries Per Second）高，1s 在计算机系统其实是一个比较大的时间跨度，以至于他反应的实际上是吞吐量而并非并发量

所以，这里说 RabbitMQ 的高并发能力其实指的是低延迟的处理，进行快速的实时反馈

## 大数据计算

### Flink

在大数据场景中，Flink 经常和 Kafka 搭配，用来消费 Kafka 的数据流

1. Kafka 生产数据（日志、用户点击、设备数据等）
2. Flink 进行实时处理（聚合、分析、清洗）
3. 处理结果存入 Kafka（本地磁盘） / 关系型数据库 / Elasticsearch

📌 示例：Flink 读取 Kafka 并统计用户点击量

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
FlinkKafkaConsumer<String> kafkaConsumer = new FlinkKafkaConsumer<>("user_clicks", new SimpleStringSchema(), properties);
DataStream<String> stream = env.addSource(kafkaConsumer);

// 统计每个用户的点击次数
stream.map(value -> new Tuple2<>(value, 1))
      .keyBy(0)
      .sum(1)
      .print();

env.execute("Kafka Stream Processing");
```

### Spark

Flink 专注于流处理，而 Spark 以批处理为主

| **对比项**     | **Flink**                         | **Spark**                    |
| -------------- | --------------------------------- | ---------------------------- |
| **计算模式**   | 主要是**流计算**，也支持批处理    | 主要是**批处理**，支持流计算 |
| **延迟**       | 毫秒级                            | 秒级                         |
| **吞吐量**     | 高吞吐，适用于高并发              | 较高吞吐，但稍逊于 Flink     |
| **故障恢复**   | Exactly-Once 语义，保证数据一致性 | At-Least-Once，可能重复计算  |
| **API 兼容性** | 提供 SQL、Java、Python API        | 提供 SQL、Scala、Java API    |

## ElasticSearch

[ElasticSearch (ES从入门到精通一篇就够了) - 不吃紫菜 - 博客园](https://www.cnblogs.com/buchizicai/p/17093719.html)

### ELK

ELK，Elastic Stack，是以 ElasticSearch 为核心的技术栈，包括 Beats、Logstash、Kibana、ElasticSerach，被广泛应用在日志数据分析、实时监控等领域

<img src="./assets/2729274-20230205171722024-1222796164.png">

作为 ELK 的核心，Elasticsearch 是一个分布式搜索引擎（索引数据库），负责存储、搜索、分析数据。他采用 Netty 作为底层通信框架，来实现高效的 **TCP 连接管理**和**数据传输**，由 Lucene 提供搜索引擎的核心 API

- Lucene：Apache 的毕业开源搜索引擎类库，基于 Java 开发

相比于 Lucene，ElasticSearch 具备下列优点

1. 支持分布式，可水平扩展
2. 提供 Restful 接口，可通过任意语言以 HTTP 方式调用

ES 的核心在于倒排索引（相对于关系型数据库的正向索引而言），在模糊搜索时速度很快（依仗于 BM25 算法）

ES 的核心评分算法：一开始是 TF-IDF 算法

<img src="./assets/2729274-20230205173433826-368331600.png">

后来是 BM25 算法（在 5.1 版本后），没错，就是这篇用到的 - [基于 BM25 算法的可搜索加密系统 | 北船](https://northboat.github.io/pages/7bc025/#jpbc-基础)

<img src="./assets/2729274-20230205173438720-1124832591.png">

与 MySQL 的对比

| **MySQL** | **Elasticsearch** | **说明**                                                     |
| --------- | ----------------- | ------------------------------------------------------------ |
| Table     | Index             | 索引（index），就是文档的集合，类似数据库的表(table)         |
| Row       | Document          | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是 JSON 格式 |
| Column    | Field             | 字段（Field），就是 JSON 文档中的字段，类似数据库中的列（Column） |
| Schema    | Mapping           | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |
| SQL       | DSL               | DSL 是 elasticsearch 提供的JSON风格的请求语句，用来操作 elasticsearch，实现CRUD |

像操纵 MySQL 一样，我们本质上都是使用 DSL 对 ES 进行 CRUD，无论是命令行还是调用 RestAPI，都是在完成这一工作

### DSL

类似于关系型数据库的 SQL，采用更为简单的 Json 格式

1️⃣ POST 命令新增文档，全部是键值对的形式进行添加

```json
POST /northboat/_doc/1
{
    "info": "真相只有一个！",
    "email": "zy@itcast.cn",
    "name": {
        "firstName": "柯",
        "lastName": "南"
    }
}
```

2️⃣ GET 查询文档

```json
GET /northboat/_doc/1
```

3️⃣ DELETE 删除文档

```json
# 根据id删除数据
DELETE /northboat/_doc/1
```

4️⃣ PUT 全量修改文档（覆盖修改），实际上是先通过 id DELETE 掉原有文档，再 POST 一个相同 id 的文档

```json
PUT /northboat/_doc/1
{
    "info": "西电凯÷CIA实验室",
    "email": "zy@itcast.cn",
    "name": {
        "firstName": "云",
        "lastName": "赵"
    }
}
```

5️⃣ POST 增量修改，只修改指定 id 匹配的文档中的**部分字段**

```json
POST /northboat/_doc/1
{
    "doc": {
         "email": "northboat@163.com",
    }
}
```

### 索引库设计

在现实场景中，我们不可能去手动创建索引库，应该是根据每个文档的关键词去创建对应的 json，那么这一过程一定是需要用到**分词器**对整个文档进行关键词的分割

我们说，创建索引库，最关键的是 mapping 映射（构建 json 映射关系），而 mapping 映射要考虑的信息包括：

- 字段名
- 字段数据类型
- 是否参与搜索
- 是否需要分词
- 如果分词，分词器是什么

在设计时

1. 依照关系型数据库的字段设计方式进行设计
2. 我们只对需要进行搜索的字段进行映射，比如主键肯定需要，而图片地址就无需参与
3. 分词器方面，可以统一使用 IK_MAX_WORD

一个 Hotel 酒店索引库示例，通过 PUT 命令创建

```json
PUT /hotel
{
  "mappings": {
    "properties": {
      "id": {
        "type": "keyword"
      },
      "name":{
        "type": "text",
        "analyzer": "ik_max_word",
        "copy_to": "all"
      },
      "address":{
        "type": "keyword",
        "index": false
      },
      "price":{
        "type": "integer"
      },
      "score":{
        "type": "integer"
      },
      "brand":{
        "type": "keyword",
        "copy_to": "all"
      },
      "city":{
        "type": "keyword",
        "copy_to": "all"
      },
      "starName":{
        "type": "keyword"
      },
      "business":{
        "type": "keyword"
      },
      "location":{
        "type": "geo_point"
      },
      "pic":{
        "type": "keyword",
        "index": false
      },
      "all":{
        "type": "text",
        "analyzer": "ik_max_word"
      }
    }
  }
}
```

几个特殊字段说明

- location：地理坐标，里面包含精度、纬度
- all：一个组合字段，其目的是将多字段的值 利用copy_to合并，提供给用户搜索

location 地理坐标

<img src="./assets/2729274-20230205172124085-626335563.png">

copy_to 属性：将当前字段拷贝到指定字段

<img src="./assets/2729274-20230205172128097-289087887.png">

当然了，在实际生产中，我们使用 Java API 来操作 ES 数据库：[Elasticsearch Clients | Elastic](https://www.elastic.co/guide/en/elasticsearch/client/index.html)

### 索引库 CRUD

引入 Java HighLevel Rest Client依赖

```xml
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
</dependency>
```

因为 SpringBoot 默认的 ES 版本是 7.6.2，所以我们需要覆盖默认的 ES 版本与自己的版本一致

```xml
<properties>
    <java.version>1.8</java.version>
    <elasticsearch.version>7.12.1</elasticsearch.version>
</properties>
```

初始化 RestHighLevelClient 并注入 Bean

```java
@Bean
public RestHighLevelClient client(){
    return new RestHighLevelClient(RestClient.builder(
        HttpHost.create("http://192.168.150.101:9200")
	));
}
```

这里为了单元测试方便，我们创建一个测试类HotelIndexTest，然后将初始化的代码编写在@BeforeEach方法中

```java
package cn.itcast.hotel;

import org.apache.http.HttpHost;
import org.elasticsearch.client.RestHighLevelClient;
import org.junit.jupiter.api.AfterEach;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.io.IOException;

public class HotelIndexTest {
    private RestHighLevelClient client;

    @BeforeEach
    void setUp() {
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create("http://192.168.150.101:9200")
        ));
    }

    @AfterEach
    void tearDown() throws IOException {
        this.client.close();
    }
}
```

CRUD 文档库 Hotel，本质上就是拼接字符串和 HTTP 请求，向 ES 数据库发送 DSL 命令，而后 ES 返回执行结果的过程

#### 创建索引库

API 文档

<img src="./assets/2729274-20230205172138463-1252488196.png">

这里

- `CreateIndexRequest`估计就是对 RestTemplate 的一层封装，用于传输 HTTP 请求
- `MAPPING_TEMPLATE`就是其对应的 DSL 语句，纯纯的一大段字符串，在某处定义一下然后使用就行

```java
package cn.itcast.hotel.constants;

public class HotelConstants {
    public static final String MAPPING_TEMPLATE = "{\n" +
            "  \"mappings\": {\n" +
            "    \"properties\": {\n" +
            "      \"id\": {\n" +
            "        \"type\": \"keyword\"\n" +
            "      },\n" +
            "      \"name\":{\n" +
            "        \"type\": \"text\",\n" +
            "        \"analyzer\": \"ik_max_word\",\n" +
            "        \"copy_to\": \"all\"\n" +
            "      },\n" +
            "      \"address\":{\n" +
            "        \"type\": \"keyword\",\n" +
            "        \"index\": false\n" +
            "      },\n" +
            "      \"price\":{\n" +
            "        \"type\": \"integer\"\n" +
            "      },\n" +
            "      \"score\":{\n" +
            "        \"type\": \"integer\"\n" +
            "      },\n" +
            "      \"brand\":{\n" +
            "        \"type\": \"keyword\",\n" +
            "        \"copy_to\": \"all\"\n" +
            "      },\n" +
            "      \"city\":{\n" +
            "        \"type\": \"keyword\",\n" +
            "        \"copy_to\": \"all\"\n" +
            "      },\n" +
            "      \"starName\":{\n" +
            "        \"type\": \"keyword\"\n" +
            "      },\n" +
            "      \"business\":{\n" +
            "        \"type\": \"keyword\"\n" +
            "      },\n" +
            "      \"location\":{\n" +
            "        \"type\": \"geo_point\"\n" +
            "      },\n" +
            "      \"pic\":{\n" +
            "        \"type\": \"keyword\",\n" +
            "        \"index\": false\n" +
            "      },\n" +
            "      \"all\":{\n" +
            "        \"type\": \"text\",\n" +
            "        \"analyzer\": \"ik_max_word\"\n" +
            "      }\n" +
            "    }\n" +
            "  }\n" +
            "}";
}
```

然后使用该字符串（DSL）对 ES 进行操控

```java
@Test
void createHotelIndex() throws IOException {
    // 1.创建Request对象
    CreateIndexRequest request = new CreateIndexRequest("hotel");
    // 2.准备请求的参数：DSL语句
    request.source(MAPPING_TEMPLATE, XContentType.JSON);
    // 3.发送请求
    client.indices().create(request, RequestOptions.DEFAULT);
}
```

#### 删除索引库

删除索引库并不需要长串的 DSL 语句，简单的`DELETE /hotel`即可，API 调用如下

```java
@Test
void testDeleteHotelIndex() throws IOException {
    // 1.创建Request对象
    DeleteIndexRequest request = new DeleteIndexRequest("hotel");
    // 2.发送请求
    client.indices().delete(request, RequestOptions.DEFAULT);
}
```

#### 查询索引库

类似于删除操作，DSL 为`GET /hotel`

```java
@Test
void testExistsHotelIndex() throws IOException {
    // 1.创建Request对象
    GetIndexRequest request = new GetIndexRequest("hotel");
    // 2.发送请求
    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
    // 3.输出
    System.err.println(exists ? "索引库已经存在！" : "索引库不存在！");
}
```

### 文档 CRUD

这里更多的是先读取 MySQL 中的数据，然后再存进 ES 中

文档操作的基本步骤：根据发送请求那步的第一个参数，发过来判断需要创建什么`XXXRequest`

1. 初始化 RestHighLevelClient
2. 创建`XXXRequest`，XXX 可以是 Index、Get、Update、Delete、Bulk
3. 准备参数（Index、Update、Bulk时需要）
4. 发送请求：调用`RestHighLevelClient.xxx()`方法，xxx 是 index、get、update、delete、bulk
5. 解析结果（Get 时需要）

ES 的查询是一门功夫，类似于 SQL 的编写，可以有很多查询条件和复合嵌套规则，以后再学吧

## 常见分布式问题

### 分布式事务

2PC：两阶段提交，将事务的提交过程分为资源准备和资源提交两个阶段，并且由事务协调者来协调所有事务参与者，如果准备阶段所有事务参与者都预留资源成功，则进行第二阶段的资源提交，否则事务协调者回滚资源

3PC：三阶段提交协议，是二阶段提交协议的改进版本，三阶段提交有两个改动点

1. 在协调者和参与者中都引入超时机制
2. 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的

TCC：一种分布式事务处理方法，它的名称来自于其三个阶段`Try, Confirm, Cancel`，这种方法主要用于处理在分布式系统中，多个服务需要协同完成一项操作时的一致性问题

### 分布式锁

由于要保证分布式系统的性能，分布式锁一般都是乐观锁，与之对应的是悲观锁

悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加 version 或 timestamp 来操作数据（比如 CAS 策略），**性能较悲观锁有很大的提高**

- 像 synchronized、Lock、ReadWriteLock 均为悲观锁
- 而原子类例如 AtomicInteger 用的实际上是 CAS 机制，所以是一个乐观锁 → 但是没有引入版本控制，所以会出现 ABA 问题（A→B→A），详见 - [原子性、单例模式和 CAS | 北船](https://northboat.github.io/pages/479c11/#什么是-cas)

还有一种乐观锁的理解：Git

- 我们只有在 push 的时候才会进行锁的检查，返回错误信息
- 无论是 add 还是 commit，都是不上锁的（乐观的默认可执行），碰到问题（push 版本不对）再去解决

当然，我们在此处只讨论分布式锁的实现，需要明确的是，分布式锁既可以是悲观的也可以是乐观的，这要根据具体场景进行设计考量

1️⃣ Redis 实现

Redission，基于 Redis 集群的分布式锁，本质上就是维护同一个键值对，作为 Lock，获取时上锁，获取前检查这个键值对是否有锁，释放时解锁

2️⃣ Zookeeper 实现

订阅发布模式下，多个 Watcher 争用一个临时节点

- 上锁：创建临时节点
- 释放：删除临时节点

### 分布式会话

即在分布式系统的诸多后端接口之间维护**唯一**的用户 Session，可以用 Redis 存放用户 Session 并设置有效期实现，用 Redis 存 JWT 也行

### 分布式 ID

在分布式系统中，要保证 ID 的唯一性，粗糙方案

1. UUID：空间大，无序
2. 数据库自增 ID：性能差，单点故障

较好的方案

1. Redis 自增 ID：多机设置不同初始 ID 和不同步长
2. 雪花算法（Snowflake）
   - 生成 64 位的 ID，包含时间戳、机器 ID 和序列号
   - 高性能、有序，但依赖时钟同步

### 分布式链路追踪

待