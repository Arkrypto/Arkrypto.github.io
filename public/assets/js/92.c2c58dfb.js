(window.webpackJsonp=window.webpackJsonp||[]).push([[92],{1359:function(t,s,a){"use strict";a.r(s);var n=a(1),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"算法考察"}},[t._v("算法考察")]),t._v(" "),s("blockquote",[s("p",[s("a",{attrs:{href:"https://leetcode.cn/problems/climbing-stairs/",target:"_blank",rel:"noopener noreferrer"}},[t._v("爬楼梯"),s("OutboundLink")],1),t._v("：假设你正在爬楼梯。需要 n 阶你才能到达楼顶。每次你可以爬 1 或 2 个台阶。问多少种不同的方法可以爬到楼顶")])]),t._v(" "),s("p",[t._v("显然，可以使用动态规划来解决问题，对于第 i 层阶梯，其登上的方式有两种，即")]),t._v(" "),s("ul",[s("li",[t._v("从"),s("code",[t._v("i-2")]),t._v("层登两步")]),t._v(" "),s("li",[t._v("从"),s("code",[t._v("i-1")]),t._v("层登一步")])]),t._v(" "),s("p",[t._v("于是有状态转移方程\n"),s("section",[s("eqn",[s("span",{staticClass:"katex-display"},[s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"}},[s("semantics",[s("mrow",[s("mi",[t._v("d")]),s("mi",[t._v("p")]),s("mo",{attrs:{stretchy:"false"}},[t._v("[")]),s("mi",[t._v("i")]),s("mo",{attrs:{stretchy:"false"}},[t._v("]")]),s("mo",[t._v("=")]),s("mrow",[s("mo",{attrs:{fence:"true"}},[t._v("{")]),s("mtable",{attrs:{rowspacing:"0.36em",columnalign:"left left",columnspacing:"1em"}},[s("mtr",[s("mtd",[s("mstyle",{attrs:{scriptlevel:"0",displaystyle:"false"}},[s("mn",[t._v("1")])],1)],1),s("mtd",[s("mstyle",{attrs:{scriptlevel:"0",displaystyle:"false"}},[s("mrow",[s("mi",[t._v("i")]),s("mo",[t._v("=")]),s("mn",[t._v("0")]),s("mi",{attrs:{mathvariant:"normal"}},[t._v("/")]),s("mn",[t._v("1")])],1)],1)],1)],1),s("mtr",[s("mtd",[s("mstyle",{attrs:{scriptlevel:"0",displaystyle:"false"}},[s("mrow")],1)],1)],1),s("mtr",[s("mtd",[s("mstyle",{attrs:{scriptlevel:"0",displaystyle:"false"}},[s("mrow",[s("mi",[t._v("d")]),s("mi",[t._v("p")]),s("mo",{attrs:{stretchy:"false"}},[t._v("[")]),s("mi",[t._v("i")]),s("mo",[t._v("−")]),s("mn",[t._v("1")]),s("mo",{attrs:{stretchy:"false"}},[t._v("]")]),s("mo",[t._v("+")]),s("mi",[t._v("d")]),s("mi",[t._v("p")]),s("mo",{attrs:{stretchy:"false"}},[t._v("[")]),s("mi",[t._v("i")]),s("mo",[t._v("−")]),s("mn",[t._v("2")]),s("mo",{attrs:{stretchy:"false"}},[t._v("]")])],1)],1)],1),s("mtd",[s("mstyle",{attrs:{scriptlevel:"0",displaystyle:"false"}},[s("mrow",[s("mi",[t._v("i")]),s("mo",[t._v("≥")]),s("mn",[t._v("2")])],1)],1)],1)],1)],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\ndp[i]=\n\\begin{cases}\n1&i=0/1\\\\\\\\\ndp[i-1]+dp[i-2]&i\\geq2\n\\end{cases}\n")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),s("span",{staticClass:"mord mathnormal"},[t._v("d")]),s("span",{staticClass:"mord mathnormal"},[t._v("p")]),s("span",{staticClass:"mopen"},[t._v("[")]),s("span",{staticClass:"mord mathnormal"},[t._v("i")]),s("span",{staticClass:"mclose"},[t._v("]")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),s("span",{staticClass:"mrel"},[t._v("=")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}})]),s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"4.32em","vertical-align":"-1.91em"}}),s("span",{staticClass:"minner"},[s("span",{staticClass:"mopen"},[s("span",{staticClass:"delimsizing mult"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"2.35em"}},[s("span",{staticStyle:{top:"-2.2em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.15em"}}),s("span",{staticClass:"delimsizinginner delim-size4"},[s("span",[t._v("⎩")])])]),s("span",{staticStyle:{top:"-2.192em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.15em"}}),s("span",{staticStyle:{height:"0.316em",width:"0.8889em"}},[s("svg",{staticStyle:{width:"0.8889em"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"0.8889em",height:"0.316em",viewBox:"0 0 888.89 316",preserveAspectRatio:"xMinYMin"}},[s("path",{attrs:{d:"M384 0 H504 V316 H384z M384 0 H504 V316 H384z"}})])])]),s("span",{staticStyle:{top:"-3.15em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.15em"}}),s("span",{staticClass:"delimsizinginner delim-size4"},[s("span",[t._v("⎨")])])]),s("span",{staticStyle:{top:"-4.292em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.15em"}}),s("span",{staticStyle:{height:"0.316em",width:"0.8889em"}},[s("svg",{staticStyle:{width:"0.8889em"},attrs:{xmlns:"http://www.w3.org/2000/svg",width:"0.8889em",height:"0.316em",viewBox:"0 0 888.89 316",preserveAspectRatio:"xMinYMin"}},[s("path",{attrs:{d:"M384 0 H504 V316 H384z M384 0 H504 V316 H384z"}})])])]),s("span",{staticStyle:{top:"-4.6em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.15em"}}),s("span",{staticClass:"delimsizinginner delim-size4"},[s("span",[t._v("⎧")])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"1.85em"}},[s("span")])])])])]),s("span",{staticClass:"mord"},[s("span",{staticClass:"mtable"},[s("span",{staticClass:"col-align-l"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"2.41em"}},[s("span",{staticStyle:{top:"-4.41em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.008em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord"},[t._v("1")])])]),s("span",{staticStyle:{top:"-2.97em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.008em"}}),s("span",{staticClass:"mord"})]),s("span",{staticStyle:{top:"-1.53em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.008em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathnormal"},[t._v("d")]),s("span",{staticClass:"mord mathnormal"},[t._v("p")]),s("span",{staticClass:"mopen"},[t._v("[")]),s("span",{staticClass:"mord mathnormal"},[t._v("i")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),s("span",{staticClass:"mord"},[t._v("1")]),s("span",{staticClass:"mclose"},[t._v("]")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),s("span",{staticClass:"mbin"},[t._v("+")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),s("span",{staticClass:"mord mathnormal"},[t._v("d")]),s("span",{staticClass:"mord mathnormal"},[t._v("p")]),s("span",{staticClass:"mopen"},[t._v("[")]),s("span",{staticClass:"mord mathnormal"},[t._v("i")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),s("span",{staticClass:"mbin"},[t._v("−")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2222em"}}),s("span",{staticClass:"mord"},[t._v("2")]),s("span",{staticClass:"mclose"},[t._v("]")])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"1.91em"}},[s("span")])])])]),s("span",{staticClass:"arraycolsep",staticStyle:{width:"1em"}}),s("span",{staticClass:"col-align-l"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"2.41em"}},[s("span",{staticStyle:{top:"-4.41em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.008em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathnormal"},[t._v("i")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),s("span",{staticClass:"mrel"},[t._v("=")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),s("span",{staticClass:"mord"},[t._v("0/1")])])]),s("span",{staticStyle:{top:"-1.53em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"3.008em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathnormal"},[t._v("i")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),s("span",{staticClass:"mrel"},[t._v("≥")]),s("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2778em"}}),s("span",{staticClass:"mord"},[t._v("2")])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"1.91em"}},[s("span")])])])])])]),s("span",{staticClass:"mclose nulldelimiter"})])])])])])])],1),t._v("\n依此思路，可得")]),t._v(" "),s("div",{staticClass:"language-c line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[t._v("class Solution "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\npublic"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("climbStairs")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        vector"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("push_back")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("push_back")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("int")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("push_back")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" dp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[t._v("1")]),s("br"),s("span",{staticClass:"line-number"},[t._v("2")]),s("br"),s("span",{staticClass:"line-number"},[t._v("3")]),s("br"),s("span",{staticClass:"line-number"},[t._v("4")]),s("br"),s("span",{staticClass:"line-number"},[t._v("5")]),s("br"),s("span",{staticClass:"line-number"},[t._v("6")]),s("br"),s("span",{staticClass:"line-number"},[t._v("7")]),s("br"),s("span",{staticClass:"line-number"},[t._v("8")]),s("br"),s("span",{staticClass:"line-number"},[t._v("9")]),s("br"),s("span",{staticClass:"line-number"},[t._v("10")]),s("br"),s("span",{staticClass:"line-number"},[t._v("11")]),s("br")])]),s("img",{attrs:{src:a(423)}}),t._v(" "),s("h2",{attrs:{id:"论文笔记"}},[t._v("论文笔记")]),t._v(" "),s("blockquote",[s("p",[t._v("阅读论文《Attention Is All You Need》或者《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》，做好论文阅读笔记并尽可能代码复现、解读代码逻辑")])]),t._v(" "),s("h2",{attrs:{id:"大模型概述"}},[t._v("大模型概述")]),t._v(" "),s("blockquote",[s("p",[t._v("说一下当前较为流行的大模型，国内外各三种，且说出他们主要针对的领域（通用 or 专有，专有的话针对哪个垂直领域）")])]),t._v(" "),s("p",[t._v("国内大模型")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("百度的ERNIE")]),t._v("：百度提出的基于知识增强的语言表示模型，主要用于自然语言处理领域，包括文本分类、情感分析、命名实体识别等")]),t._v(" "),s("li",[s("strong",[t._v("中文BERT（BERT-wwm）")]),t._v("：这是对Google的BERT模型进行了改进和优化，使其更适合中文语境，通常应用于通用自然语言处理任务，如问答系统、语义理解等")]),t._v(" "),s("li",[s("strong",[t._v("华为的MindSpore")]),t._v("：虽然不是一个单一的模型，但华为的MindSpore是一个用于构建和训练大规模深度学习模型的框架，可以支持各种领域的应用，包括自然语言处理、计算机视觉等")])]),t._v(" "),s("p",[t._v("国外大模型")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("OpenAI的GPT（Generative Pre-trained Transformer）系列")]),t._v("：包括GPT-3等版本，主要应用于自然语言处理领域，如文本生成、对话系统、文本分类等，其强大的生成能力备受关注")]),t._v(" "),s("li",[s("strong",[t._v("Google的BERT（Bidirectional Encoder Representations from Transformers）")]),t._v("：作为一种预训练的语言表示模型，BERT在自然语言处理领域表现出色，广泛用于文本分类、语义理解、命名实体识别等任务")]),t._v(" "),s("li",[s("strong",[t._v("Facebook的RoBERTa")]),t._v("：RoBERTa是对BERT进行了改进的模型，通过更大规模的数据集和更长的预训练时间来提高性能，同样应用于自然语言处理领域的各种任务")])]),t._v(" "),s("p",[t._v("这些大模型可以在各种领域发挥作用，包括但不限于通用自然语言处理、计算机视觉、推荐系统等。有些模型可能更适用于特定领域，如ERNIE在中文语境下的表现更好，而GPT系列在文本生成任务上有独特优势")]),t._v(" "),s("blockquote",[s("p",[t._v("请说一下大模型训练、微调的手段有哪些")])]),t._v(" "),s("p",[t._v("大型模型的训练和微调通常涉及到以下几种主要手段")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("预训练（Pre-training）")]),t._v("：在大规模数据集上进行的初始训练，目的是使模型学习到丰富的语言表示。预训练通常采用无监督或半监督的方式，在文本数据上进行预测任务，如语言建模（预测下一个词）、掩码语言建模（预测掩码词）、预测下一个句子等")]),t._v(" "),s("li",[s("strong",[t._v("微调（Fine-tuning）")]),t._v("：将预训练好的模型在特定任务的有标签数据集上进行进一步的训练，以使其适应该任务的特定要求。微调可以是在整个模型上进行，也可以只在模型的一部分层次上进行")]),t._v(" "),s("li",[s("strong",[t._v("自适应学习率（Adaptive Learning Rate）")]),t._v("：由于大型模型参数数量庞大，学习率的设置尤为重要。自适应学习率算法可以根据参数的梯度情况动态调整学习率，以保证训练的稳定性和收敛性")]),t._v(" "),s("li",[s("strong",[t._v("正则化（Regularization）")]),t._v("：用于减少模型的过拟合风险。常见的正则化技术包括L1正则化和L2正则化，它们通过对模型参数进行惩罚来限制参数的大小")]),t._v(" "),s("li",[s("strong",[t._v("批量归一化（Batch Normalization）")]),t._v("：在深度神经网络中，批量归一化可以加速模型的收敛，减少训练时间，并且有助于模型的泛化性能")]),t._v(" "),s("li",[s("strong",[t._v("参数初始化（Parameter Initialization）")]),t._v("：好的参数初始化策略可以加速模型的收敛并提高模型的性能。常见的参数初始化方法包括随机初始化、Xavier初始化和He初始化等")]),t._v(" "),s("li",[s("strong",[t._v("数据增强（Data Augmentation）")]),t._v("：在微调阶段，通过对训练数据进行变换、旋转、剪裁等操作，可以增加数据的多样性，提高模型的泛化能力")]),t._v(" "),s("li",[s("strong",[t._v("迁移学习（Transfer Learning）")]),t._v("：利用预训练好的模型在特定领域进行微调，可以加速模型的收敛并提高模型的性能，尤其是在数据量有限的情况下")])]),t._v(" "),s("p",[t._v("这些手段可以单独或组合使用，根据具体任务和数据情况来选择合适的训练和微调策略")]),t._v(" "),s("blockquote",[s("p",[t._v("如果有优化和部署经验，请进一步解说其中的技术点")])]),t._v(" "),s("p",[t._v("在本地笔记本电脑不同操作系统上（Windows11 / Manjaro / ArchLinux）部署过清华的开源语言大模型 ChatGLM-6B 并分别以 32G CPU 和 8G GPU 成功运行")]),t._v(" "),s("ul",[s("li",[t._v("Github："),s("a",{attrs:{href:"https://github.com/THUDM/ChatGLM-6B",target:"_blank",rel:"noopener noreferrer"}},[t._v("THUDM/ChatGLM-6B: ChatGLM-6B: An Open Bilingual Dialogue Language Model | 开源双语对话语言模型 (github.com)"),s("OutboundLink")],1)]),t._v(" "),s("li",[t._v("Hugging Face："),s("a",{attrs:{href:"https://huggingface.co/THUDM/chatglm-6b",target:"_blank",rel:"noopener noreferrer"}},[t._v("THUDM/chatglm-6b · Hugging Face"),s("OutboundLink")],1)])]),t._v(" "),s("p",[t._v("采用 Web 可视化操作微调过相关参数，但对于其中优化细节并不十分了解，以下为搜索得到")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("模型压缩和量化（Model Compression and Quantization）")]),t._v("：针对大型模型的参数数量庞大和计算需求高的问题，可以采用模型压缩和量化技术来减少模型的大小和计算量。例如，剪枝（Pruning）可以去除模型中冗余的连接和参数，量化（Quantization）可以将模型参数从浮点数转换为较低位数的整数，从而减少存储和计算量")]),t._v(" "),s("li",[s("strong",[t._v("硬件加速器的使用（Hardware Acceleration）")]),t._v("：利用专门的硬件加速器（如GPU、TPU等）来加速大型模型的推理和训练过程。这些硬件加速器通常能够提供比通用处理器更高的计算性能和能效比，从而加速模型的运行")]),t._v(" "),s("li",[s("strong",[t._v("模型量化和量化训练（Quantization-aware Training）")]),t._v("：在训练过程中考虑到模型量化后的精度损失，采用量化感知的训练方法，从而在量化后保持模型的性能")]),t._v(" "),s("li",[s("strong",[t._v("分布式训练（Distributed Training）")]),t._v("：利用多个计算节点或者多个设备进行模型训练，加速训练过程并处理大规模数据。分布式训练需要设计合适的通信和同步机制，以确保模型参数的一致性")]),t._v(" "),s("li",[s("strong",[t._v("模型蒸馏（Model Distillation）")]),t._v("：利用较小、高效的模型来“蒸馏”（distill）大型模型的知识，从而在保留性能的情况下减少模型的大小和计算需求")]),t._v(" "),s("li",[s("strong",[t._v("缓存优化和预取优化（Cache and Prefetch Optimization）")]),t._v("：利用硬件缓存和预取机制来优化模型的内存访问模式，减少内存访问延迟，提高模型的运行效率")]),t._v(" "),s("li",[s("strong",[t._v("模型并行和数据并行（Model Parallelism and Data Parallelism）")]),t._v("：将模型参数或训练数据分布到多个设备或计算节点上，并行地进行模型计算和训练，以提高训练速度和计算效率")]),t._v(" "),s("li",[s("strong",[t._v("模型部署的优化（Deployment Optimization）")]),t._v("：将训练好的模型部署到生产环境中时，需要考虑到模型的性能、延迟、吞吐量等方面的要求，并对模型进行相应的优化，以满足实际应用的需求")])]),t._v(" "),s("p",[t._v("这些技术点通常会结合使用，以优化和部署大型模型，从而在保持模型性能的同时，提高模型的效率和可用性")]),t._v(" "),s("blockquote",[s("p",[t._v("请说一下目前大模型急待解决的缺陷在哪里")])]),t._v(" "),s("p",[t._v("目前大型模型仍存在一些急待解决的缺陷，主要包括")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("能源消耗和计算资源需求高")]),t._v("：大型模型需要庞大的计算资源和能源来进行训练和推理，这给环境造成了负担，也限制了大型模型的广泛应用")]),t._v(" "),s("li",[s("strong",[t._v("模型的可解释性差")]),t._v("：大型模型通常具有数以亿计的参数，其内部机理复杂，导致模型的预测结果难以解释，这在一些应用场景下不利于模型的应用和部署")]),t._v(" "),s("li",[s("strong",[t._v("数据隐私和安全性问题")]),t._v("：大型模型通常需要大量的数据进行训练，在数据隐私和安全性方面存在一定的风险，例如模型可能会记住训练数据中的敏感信息")]),t._v(" "),s("li",[s("strong",[t._v("样本偏差和数据分布偏移")]),t._v("：大型模型在训练过程中往往对数据分布敏感，当面临新领域或新任务时，可能会出现样本偏差和数据分布偏移的问题，导致模型性能下降")]),t._v(" "),s("li",[s("strong",[t._v("社会和伦理问题")]),t._v("：大型模型的应用可能会引发社会和伦理方面的问题，例如模型生成的内容可能包含有害信息、歧视性言论等，需要制定相应的政策和规范来管理模型的应用")]),t._v(" "),s("li",[s("strong",[t._v("通用性和泛化能力有限")]),t._v("：虽然大型模型在许多任务上表现出色，但其泛化能力仍有待改进，特别是在面对不同领域、不同语种或低资源语种的情况下")])]),t._v(" "),s("p",[t._v("解决这些缺陷需要跨学科的合作，包括算法研究、硬件优化、数据管理、隐私保护等方面的工作。同时，也需要制定相关政策和规范，确保大型模型的应用能够符合社会和伦理的要求")])])}),[],!1,null,null,null);s.default=e.exports},423:function(t,s,a){t.exports=a.p+"assets/img/image-20240307202659652.6254e65c.png"}}]);